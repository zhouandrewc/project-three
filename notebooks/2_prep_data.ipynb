{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:27:59.647163Z",
     "iopub.status.busy": "2020-10-31T18:27:59.646941Z",
     "iopub.status.idle": "2020-10-31T18:27:59.651361Z",
     "shell.execute_reply": "2020-10-31T18:27:59.650672Z",
     "shell.execute_reply.started": "2020-10-31T18:27:59.647140Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from util.parsing import get_variables\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from util.cleaning import agg_race_cah, agg_hispanicity, filter_na_response, has_bachelors, get_race, get_race_ta17, is_hispanic_cah, get_env_type, live_w_both_parents, is_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected relevant variables and stored the data in several SQL tables in ```sql_logic.ipynb```. Now we use a SQL query to join these tables so we can create our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:00.751726Z",
     "iopub.status.busy": "2020-10-31T18:28:00.751486Z",
     "iopub.status.idle": "2020-10-31T18:28:00.839160Z",
     "shell.execute_reply": "2020-10-31T18:28:00.838534Z",
     "shell.execute_reply.started": "2020-10-31T18:28:00.751699Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "uri = \"postgres+psycopg2://zhou@localhost:5432/psid\"\n",
    "engine = create_engine(uri, echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T19:58:38.613431Z",
     "iopub.status.busy": "2020-10-30T19:58:38.613203Z",
     "iopub.status.idle": "2020-10-30T19:58:38.617025Z",
     "shell.execute_reply": "2020-10-30T19:58:38.616127Z",
     "shell.execute_reply.started": "2020-10-30T19:58:38.613407Z"
    }
   },
   "source": [
    "```sql\n",
    "SELECT * from ind17 \n",
    "LEFT JOIN child02 on child02.indid01=ind17.indid01 AND child02.famid01=ind17.famid01 \n",
    "LEFT JOIN assess ON assess.indid01 = ind17.indid01 AND assess.famid01=ind17.famid01 \n",
    "LEFT JOIN demog ON demog.indid01 = ind17.indid01 AND demog.famid01=ind17.famid01 \n",
    "LEFT JOIN fam01 ON fam01.indid01 = ind17.indid01 AND demog.famid68=ind17.famid68\n",
    "WHERE ind17.indid01<>0 AND ind17.cds_interview=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:01.563012Z",
     "iopub.status.busy": "2020-10-31T18:28:01.562795Z",
     "iopub.status.idle": "2020-10-31T18:28:01.691403Z",
     "shell.execute_reply": "2020-10-31T18:28:01.690879Z",
     "shell.execute_reply.started": "2020-10-31T18:28:01.562988Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_get_join_data = \"SELECT * FROM ind17 \\\n",
    "LEFT JOIN child02 on child02.indid01 = ind17.indid01 AND child02.famid01 = ind17.famid01 \\\n",
    "LEFT JOIN assess ON assess.indid01 = ind17.indid01 AND assess.famid01 = ind17.famid01 \\\n",
    "LEFT JOIN demog ON demog.indid01 = ind17.indid01 AND demog.famid01 = ind17.famid01 \\\n",
    "LEFT JOIN fam01 ON fam01.famid01 = ind17.famid01 AND fam01.famid68 = ind17.famid68 \\\n",
    "LEFT JOIN ta17 ON ta17.famid17 = ind17.famid17 AND ta17.indid17 = ind17.indid17 \\\n",
    "LEFT JOIN pcg02 ON pcg02.famid01 = ind17.famid01 AND pcg02.indid01 = ind17.indid01 \\\n",
    "LEFT JOIN wlth01 ON wlth01.famid01 = ind17.famid01 \\\n",
    "WHERE ind17.indid01<>0 AND ind17.cds_interview=1\"\n",
    "\n",
    "prelim_data_df = pd.read_sql_query(sql_get_join_data, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate columns from the joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:02.754740Z",
     "iopub.status.busy": "2020-10-31T18:28:02.754506Z",
     "iopub.status.idle": "2020-10-31T18:28:02.759546Z",
     "shell.execute_reply": "2020-10-31T18:28:02.758853Z",
     "shell.execute_reply.started": "2020-10-31T18:28:02.754715Z"
    }
   },
   "outputs": [],
   "source": [
    "prelim_data_df = prelim_data_df.loc[:,~prelim_data_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We isolate various features of interest through perusing the codebooks for the PSID surveys: math and reading assessment percentile scores from 2002; wealth and income of the family in 2001; whether the child lived with both parents in 2001; the household's food security status in 2001; the child's race; and \"urbanicity\" variable indicating where the child's neighborhood/county fall on the [Beale Rural-Urban Continuum](https://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx).\n",
    "\n",
    "Our continuous variables are ```math_score```, ```reading_score```, ```food_security```, ```wealth```, and ```income```.\n",
    "\n",
    "Our binary categorical variables are ```white_only``` , ```black```, ```asian```, and ```hispanic```. \n",
    "\n",
    "We have one nominal categorical variables with several categories: our urbanicity variable, which we denote ```environment type```.  Its categories are ```met_central```, ```met_fringe```, ```met_small```, ```urb_met```, ```urb_nonmet```, and ```rural```.\n",
    "\n",
    "Our response variable is ```grad_bach```, whether the individual received a bachelor's degree by 2017. \n",
    "\n",
    "We have an additional variable ```survey_weight``` which we use to weight samples during training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T17:57:22.600456Z",
     "iopub.status.busy": "2020-10-31T17:57:22.600204Z",
     "iopub.status.idle": "2020-10-31T17:57:22.603118Z",
     "shell.execute_reply": "2020-10-31T17:57:22.602483Z",
     "shell.execute_reply.started": "2020-10-31T17:57:22.600427Z"
    }
   },
   "source": [
    "### Remove Non-responses\n",
    "\n",
    "We remove all non-responses for our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:04.419589Z",
     "iopub.status.busy": "2020-10-31T18:28:04.419363Z",
     "iopub.status.idle": "2020-10-31T18:28:04.588137Z",
     "shell.execute_reply": "2020-10-31T18:28:04.587574Z",
     "shell.execute_reply.started": "2020-10-31T18:28:04.419563Z"
    }
   },
   "outputs": [],
   "source": [
    "prelim_data_df = prelim_data_df[prelim_data_df.apply(filter_na_response, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring Race/Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The race/ethnicity data are scattered far and wide among many tables, due to some surveys only interviewing a subset of the study members; some individuals responding to one survey but not another; some surveys where individuals responded on their own behalf and others where parents and caretakers responded on a child's behalf, etc. We take pains to sift through this data.\n",
    "\n",
    "We represent \"White,\" \"Black,\" \"Asian,\" and \"Hispanic\" as binary 0-1 variables, with 1 indicating the individual is of that race and 0 indicating otherwise. Additionally, we have a \"White Only\" feature inferred from the aforementioned 4 variables; we use this feature along with \"Black,\" \"Asian,\" and \"Hispanic\" in our modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Childhood and Adoption History data, parents and caretakers indicated the race of their charges. There are potentially multiple responses for each child, so we aggregate them in an array and merge with our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:05.728539Z",
     "iopub.status.busy": "2020-10-31T18:28:05.728314Z",
     "iopub.status.idle": "2020-10-31T18:28:08.480033Z",
     "shell.execute_reply": "2020-10-31T18:28:08.479469Z",
     "shell.execute_reply.started": "2020-10-31T18:28:05.728515Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cah = \"SELECT * FROM cah\"\n",
    "cah_data_df = pd.read_sql_query(get_cah, con=engine)\n",
    "\n",
    "# aggregate responses on the child's behalf\n",
    "# the race_code variables indicate whether the responder said the child\n",
    "# was white, asian, or black. separately, a hispanicity variable indicated\n",
    "# the specific hispanic background of a child. \n",
    "cah_data_df_grouped = cah_data_df.groupby([\"famid68\", \"indid68\"]).agg({\n",
    "    \"hispanicity\": agg_hispanicity,\n",
    "    \"race_code_cah_1\": agg_race_cah,\n",
    "    \"race_code_cah_2\": agg_race_cah,\n",
    "    \"race_code_cah_3\": agg_race_cah\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:08.481311Z",
     "iopub.status.busy": "2020-10-31T18:28:08.481160Z",
     "iopub.status.idle": "2020-10-31T18:28:08.500914Z",
     "shell.execute_reply": "2020-10-31T18:28:08.500357Z",
     "shell.execute_reply.started": "2020-10-31T18:28:08.481293Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = prelim_data_df.merge(cah_data_df_grouped, on=[\"famid68\", \"indid68\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:08.502453Z",
     "iopub.status.busy": "2020-10-31T18:28:08.502289Z",
     "iopub.status.idle": "2020-10-31T18:28:08.685044Z",
     "shell.execute_reply": "2020-10-31T18:28:08.684061Z",
     "shell.execute_reply.started": "2020-10-31T18:28:08.502433Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill these variables with empty arrays for children who didn't have anyone respond on their behalf during the CAH survey\n",
    "data_df[\"race_code_cah_1\"] = data_df[\"race_code_cah_1\"].apply(lambda x: x if not x else [])\n",
    "data_df[\"race_code_cah_2\"] = data_df[\"race_code_cah_2\"].apply(lambda x: x if not x else [])\n",
    "data_df[\"race_code_cah_3\"] = data_df[\"race_code_cah_3\"].apply(lambda x: x if not x else [])\n",
    "\n",
    "# get race listed in the child02 survey\n",
    "data_df[\"race\"] = data_df[\"race_code\"].apply(get_race)\n",
    "\n",
    "# get race listed in the ta17 survey\n",
    "data_df[\"race17_1\"] = data_df[\"race_code17_1\"].apply(get_race_ta17)\n",
    "data_df[\"race17_2\"] = data_df[\"race_code17_2\"].apply(get_race_ta17)\n",
    "\n",
    "# infer race from all of the above\n",
    "data_df[\"asian\"] = data_df.apply(is_race(\"asian\"), axis=1)\n",
    "data_df[\"black\"] = data_df.apply(is_race(\"black\"), axis=1)\n",
    "data_df[\"white\"] = data_df.apply(is_race(\"white\"), axis=1)\n",
    "data_df[\"hispanic\"] = data_df.apply(lambda row: 1 if is_race(\"hispanic\")(row) or row[\"hispanicity\"] else 0, axis=1)\n",
    "\n",
    "data_df[\"white_only\"] = data_df.apply(lambda row: 1 if row[\"white\"] == 1 and row[\"hispanic\"] == 0 and row[\"black\"] == 0 and row[\"asian\"] == 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income and Wealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove some extreme income/wealth outliers so as to improve our modeling. To do so, we cap income at 2 standard deviations above the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:08.687128Z",
     "iopub.status.busy": "2020-10-31T18:28:08.686892Z",
     "iopub.status.idle": "2020-10-31T18:28:08.697557Z",
     "shell.execute_reply": "2020-10-31T18:28:08.697005Z",
     "shell.execute_reply.started": "2020-10-31T18:28:08.687111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle income outliers by capping income and wealth at +2 std for now\n",
    "inc_cap = data_df[\"total_fam_income00\"].mean() + 2*data_df[\"total_fam_income00\"].std()\n",
    "data_df[\"total_fam_income00_cap\"] = data_df[\"total_fam_income00\"].clip(upper=inc_cap)\n",
    "wealth_cap = data_df[\"wealth_w_equity01\"].mean() + 2*data_df[\"wealth_w_equity01\"].std()\n",
    "data_df[\"wealth_w_equity01_cap\"] = data_df[\"wealth_w_equity01\"].clip(upper=wealth_cap)\n",
    "data_df = data_df.replace({\"math_score02\": 999, \"reading_score02\": 999}, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Math and Reading Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute math and reading scores from the income and wealth variables.\n",
    "\n",
    "N.B. We perform this imputation mainly as an exercise. We use wealth and income as they are the most convenient variables to impute with, and recognize that this strategy suffers from various flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:08.698591Z",
     "iopub.status.busy": "2020-10-31T18:28:08.698450Z",
     "iopub.status.idle": "2020-10-31T18:28:09.984762Z",
     "shell.execute_reply": "2020-10-31T18:28:09.984205Z",
     "shell.execute_reply.started": "2020-10-31T18:28:08.698573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use income and wealth, our primary continuous variables, to impute math and reading scores\n",
    "data_df = data_df.replace({\"math_score02\": 999, \"reading_score02\": 999}, np.nan)\n",
    "temp_impute_df = data_df[[\"math_score02\", \"reading_score02\", \"wealth_w_equity01_cap\", \"total_fam_income00_cap\"]]\n",
    "\n",
    "imp = IterativeImputer(random_state=0, estimator=RandomForestRegressor())\n",
    "data_df_imputed = pd.DataFrame(imp.fit_transform(temp_impute_df), index=temp_impute_df.index, columns=temp_impute_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:09:05.504595Z",
     "iopub.status.busy": "2020-10-31T18:09:05.504378Z",
     "iopub.status.idle": "2020-10-31T18:09:05.507209Z",
     "shell.execute_reply": "2020-10-31T18:09:05.506448Z",
     "shell.execute_reply.started": "2020-10-31T18:09:05.504572Z"
    }
   },
   "source": [
    "### Handle Other Variables\n",
    "\n",
    "We construct our last few features and our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:09.986107Z",
     "iopub.status.busy": "2020-10-31T18:28:09.985949Z",
     "iopub.status.idle": "2020-10-31T18:28:10.114933Z",
     "shell.execute_reply": "2020-10-31T18:28:10.114371Z",
     "shell.execute_reply.started": "2020-10-31T18:28:09.986086Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df[\"age\"] = data_df[\"age_01\"] + 16\n",
    "data_df[\"live_w_both_parents\"] = data_df.apply(live_w_both_parents, axis=1)\n",
    "data_df[\"environment_type\"] = data_df[\"rural_urban_code01\"].apply(get_env_type)\n",
    "\n",
    "data_df[\"grad_bach\"] = data_df.apply(has_bachelors, axis=1).map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Cleaning Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove a few data points without and environment type, and limit our sample to people over age 22; younger individuals are increasingly unlikely to have graduated with a bachelor's degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:10.290969Z",
     "iopub.status.busy": "2020-10-31T18:28:10.290759Z",
     "iopub.status.idle": "2020-10-31T18:28:10.297718Z",
     "shell.execute_reply": "2020-10-31T18:28:10.297137Z",
     "shell.execute_reply.started": "2020-10-31T18:28:10.290946Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = data_df[~data_df[\"environment_type\"].isnull()]\n",
    "data_df = data_df[data_df[\"age\"] >= 22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:11:06.331926Z",
     "iopub.status.busy": "2020-10-31T18:11:06.331748Z",
     "iopub.status.idle": "2020-10-31T18:11:06.335279Z",
     "shell.execute_reply": "2020-10-31T18:11:06.334560Z",
     "shell.execute_reply.started": "2020-10-31T18:11:06.331909Z"
    }
   },
   "source": [
    "Store the imputed data into our original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:11.215305Z",
     "iopub.status.busy": "2020-10-31T18:28:11.215081Z",
     "iopub.status.idle": "2020-10-31T18:28:11.221007Z",
     "shell.execute_reply": "2020-10-31T18:28:11.220309Z",
     "shell.execute_reply.started": "2020-10-31T18:28:11.215281Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df[[\"math_score02\", \"reading_score02\", \"wealth_w_equity01_cap\", \"total_fam_income00_cap\"]] = data_df_imputed[[\"math_score02\", \"reading_score02\", \"wealth_w_equity01_cap\", \"total_fam_income00_cap\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:12:07.847522Z",
     "iopub.status.busy": "2020-10-31T18:12:07.847298Z",
     "iopub.status.idle": "2020-10-31T18:12:07.850070Z",
     "shell.execute_reply": "2020-10-31T18:12:07.849399Z",
     "shell.execute_reply.started": "2020-10-31T18:12:07.847498Z"
    }
   },
   "source": [
    "## Final Touches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename variables for ease of use in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:12.948637Z",
     "iopub.status.busy": "2020-10-31T18:28:12.948383Z",
     "iopub.status.idle": "2020-10-31T18:28:12.952919Z",
     "shell.execute_reply": "2020-10-31T18:28:12.952303Z",
     "shell.execute_reply.started": "2020-10-31T18:28:12.948608Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = data_df.rename({\"math_score02\": \"math_score\", \"reading_score02\": \"reading_score\",\\\n",
    "                    \"wealth_w_equity01_cap\": \"wealth\", \"total_fam_income00_cap\": \"income\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:28:14.318273Z",
     "iopub.status.busy": "2020-10-31T18:28:14.318019Z",
     "iopub.status.idle": "2020-10-31T18:28:14.323034Z",
     "shell.execute_reply": "2020-10-31T18:28:14.322359Z",
     "shell.execute_reply.started": "2020-10-31T18:28:14.318245Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = data_df[['math_score', 'reading_score', 'wealth', 'income', 'grad_bach', 'survey_weight', 'environment_type', 'age', 'white_only', 'black', 'asian', 'live_w_both_parents', 'food_security', 'hispanic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T18:29:15.903463Z",
     "iopub.status.busy": "2020-10-31T18:29:15.903249Z",
     "iopub.status.idle": "2020-10-31T18:29:15.921669Z",
     "shell.execute_reply": "2020-10-31T18:29:15.921105Z",
     "shell.execute_reply.started": "2020-10-31T18:29:15.903440Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.to_csv(\"../data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
